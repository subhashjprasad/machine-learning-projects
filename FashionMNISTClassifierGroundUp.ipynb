{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMM/vSytgZu571jv1w7y3II",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhashjprasad/machine-learning-projects/blob/main/FashionMNISTClassifierGroundUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and DataLoader"
      ],
      "metadata": {
        "id": "hicQf9lLsfoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDg-JXA5raoD",
        "outputId": "5f096380-66e5-41ee-a8b8-4ede65a3795b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12453988.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 198648.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3764994.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15935259.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders for our datasets; shuffle for training, not for validation\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Report split sizes\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print('  '.join(classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "AbQGUQJLsdeh",
        "outputId": "62c31638-ee09-4c19-a991-57d9ca03f79c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle Boot  Ankle Boot  Sandal  T-shirt/top\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "pbWcfzxZqLZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class GarmentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GarmentClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GarmentClassifier()"
      ],
      "metadata": {
        "id": "a5wPYfK-uv7O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function"
      ],
      "metadata": {
        "id": "yOQUzYfjqF11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
        "# Represents the model's confidence in each of the 10 classes for a given input\n",
        "dummy_outputs = torch.rand(4, 10)\n",
        "# Represents the correct class among the 10 being tested\n",
        "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
        "\n",
        "print(dummy_outputs)\n",
        "print(dummy_labels)\n",
        "\n",
        "loss = loss_fn(dummy_outputs, dummy_labels)\n",
        "print('Total loss for this batch: {}'.format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z0XOmKhp_ou",
        "outputId": "1e7c4697-9ac3-4f7f-de30-a764b840871c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7332, 0.8122, 0.8120, 0.1948, 0.8944, 0.6700, 0.0402, 0.5968, 0.2177,\n",
            "         0.4613],\n",
            "        [0.1264, 0.6303, 0.1671, 0.7980, 0.7991, 0.1825, 0.4508, 0.9780, 0.9890,\n",
            "         0.2127],\n",
            "        [0.3648, 0.0976, 0.2862, 0.7206, 0.1897, 0.2818, 0.0379, 0.8577, 0.2461,\n",
            "         0.4900],\n",
            "        [0.1328, 0.2582, 0.7597, 0.9326, 0.5531, 0.8932, 0.4542, 0.0320, 0.2819,\n",
            "         0.0297]])\n",
            "tensor([1, 5, 3, 7])\n",
            "Total loss for this batch: 2.3770804405212402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer"
      ],
      "metadata": {
        "id": "wszRZJPDqMgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "mGqvHSluqNsY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "kOyNtIspqeFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "Aabqg54EqcYf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per-Epoch Activity"
      ],
      "metadata": {
        "id": "fxIznuKHrM5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl3s6dN1q-Au",
        "outputId": "12ea1715-8a1d-4108-967c-ef69aa67cd6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 1.6824021390527486\n",
            "  batch 2000 loss: 0.8654571528341621\n",
            "  batch 3000 loss: 0.7145391858555377\n",
            "  batch 4000 loss: 0.6588479601535946\n",
            "  batch 5000 loss: 0.6191045382341835\n",
            "  batch 6000 loss: 0.5466439823504771\n",
            "  batch 7000 loss: 0.5512895741972607\n",
            "  batch 8000 loss: 0.51554218513472\n",
            "  batch 9000 loss: 0.48495657944766574\n",
            "  batch 10000 loss: 0.45842779511830306\n",
            "  batch 11000 loss: 0.44225953587924594\n",
            "  batch 12000 loss: 0.4669859495083801\n",
            "  batch 13000 loss: 0.4345039644143544\n",
            "  batch 14000 loss: 0.4157395976551343\n",
            "  batch 15000 loss: 0.42911526723578575\n",
            "LOSS train 0.42911526723578575 valid 0.43576347827911377\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 0.4041369556320133\n",
            "  batch 2000 loss: 0.39604816080682215\n",
            "  batch 3000 loss: 0.37963264757374415\n",
            "  batch 4000 loss: 0.38178179033269405\n",
            "  batch 5000 loss: 0.3781901894655457\n",
            "  batch 6000 loss: 0.38533499381443836\n",
            "  batch 7000 loss: 0.3776316481092072\n",
            "  batch 8000 loss: 0.3758435191868339\n",
            "  batch 9000 loss: 0.3783595634069643\n",
            "  batch 10000 loss: 0.3627250504016556\n",
            "  batch 11000 loss: 0.3715484825718449\n",
            "  batch 12000 loss: 0.34639405820780667\n",
            "  batch 13000 loss: 0.37162219652120254\n",
            "  batch 14000 loss: 0.3593025274310494\n",
            "  batch 15000 loss: 0.332593275349529\n",
            "LOSS train 0.332593275349529 valid 0.37754523754119873\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.3298283806833788\n",
            "  batch 2000 loss: 0.3281601937230007\n",
            "  batch 3000 loss: 0.3198902639023727\n",
            "  batch 4000 loss: 0.3171320310901574\n",
            "  batch 5000 loss: 0.3267889552736451\n",
            "  batch 6000 loss: 0.3468571803011\n",
            "  batch 7000 loss: 0.30788880818750475\n",
            "  batch 8000 loss: 0.3269598806673166\n",
            "  batch 9000 loss: 0.3258865628609783\n",
            "  batch 10000 loss: 0.3367316526642244\n",
            "  batch 11000 loss: 0.32768977361665746\n",
            "  batch 12000 loss: 0.3255569044571603\n",
            "  batch 13000 loss: 0.3325190839529096\n",
            "  batch 14000 loss: 0.30376964442641474\n",
            "  batch 15000 loss: 0.3264865368841056\n",
            "LOSS train 0.3264865368841056 valid 0.34755077958106995\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.31446763000037753\n",
            "  batch 2000 loss: 0.29638762201818464\n",
            "  batch 3000 loss: 0.29098193285283924\n",
            "  batch 4000 loss: 0.294550012254942\n",
            "  batch 5000 loss: 0.28463173355344773\n",
            "  batch 6000 loss: 0.3233088658744673\n",
            "  batch 7000 loss: 0.2911710429856612\n",
            "  batch 8000 loss: 0.2940491238401155\n",
            "  batch 9000 loss: 0.29407831652921596\n",
            "  batch 10000 loss: 0.30582126971124673\n",
            "  batch 11000 loss: 0.30484975680376375\n",
            "  batch 12000 loss: 0.2916569250939792\n",
            "  batch 13000 loss: 0.300284360263744\n",
            "  batch 14000 loss: 0.3080884593055889\n",
            "  batch 15000 loss: 0.2868633808156574\n",
            "LOSS train 0.2868633808156574 valid 0.33466291427612305\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.27053965331275687\n",
            "  batch 2000 loss: 0.27655119988558724\n",
            "  batch 3000 loss: 0.2722051902849189\n",
            "  batch 4000 loss: 0.2718423721225845\n",
            "  batch 5000 loss: 0.2858411711107328\n",
            "  batch 6000 loss: 0.27876322949971655\n",
            "  batch 7000 loss: 0.2850618681320775\n",
            "  batch 8000 loss: 0.28796486650808945\n",
            "  batch 9000 loss: 0.2841680652320501\n",
            "  batch 10000 loss: 0.2616168871022019\n",
            "  batch 11000 loss: 0.26384660368618645\n",
            "  batch 12000 loss: 0.27311697119275413\n",
            "  batch 13000 loss: 0.2940864389768831\n",
            "  batch 14000 loss: 0.2768215905599645\n",
            "  batch 15000 loss: 0.2921141776984623\n",
            "LOSS train 0.2921141776984623 valid 0.3340325951576233\n"
          ]
        }
      ]
    }
  ]
}